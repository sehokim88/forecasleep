{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from functions import (\n",
    "    datespace, parse_datetime, import_concat, stitch_drop_append,\n",
    "    expand_input_time, get_input_bed, \n",
    "    get_delta, get_delta_scale, get_p_day, get_diff, get_avg, get_var, \n",
    "    get_top5, get_bottom5,\n",
    "    estimator_cv_scores, estimator_cv_scores2)\n",
    "\n",
    "from classes import (TimeScaler, AvgRatioFiller, MatrixPipeline, OneHotEncoder, \n",
    "                    ZeroFiller, ChainTransformer, StandardScaler, AvgFiller)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_all_sleep = pd.read_csv('data/sleep_archive.csv')\n",
    "raw_all_sleep.columns = ['start', 'end', 'asleep','awake','awakening','bed',' rem','light','deep']\n",
    "raw_all_sleep['start'] = raw_all_sleep['start'].apply(parse_datetime)\n",
    "raw_all_sleep['end'] = raw_all_sleep['end'].apply(parse_datetime)\n",
    "raw_all_sleep.drop_duplicates(inplace=True)\n",
    "raw_all_sleep.sort_values('start', inplace=True)\n",
    "raw_all_sleep.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import hr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # raw_hr\n",
    "# raw_hr = pd.read_csv('data/hr_archive.csv')\n",
    "# raw_hr['date_time']=raw_hr['date_time'].apply(parse_datetime)\n",
    "# raw_hr['date']=raw_hr['date_time'].apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # exp_hr\n",
    "# wake = np.empty(len(exp_sleep))\n",
    "# wake[1:] = exp_sleep.loc[:len(exp_sleep)-2, 'end']\n",
    "# exp_sleep['wake'] = list(map(lambda x: pd.to_datetime(x), wake))\n",
    "# exp_hr = raw_hr.merge(exp_sleep[['date','start','wake']], on='date', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fil_hr\n",
    "# mask1 = exp_hr['date_time'] >= exp_hr['wake']\n",
    "# mask2 = exp_hr['date_time'] < exp_hr['start']\n",
    "# fil_hr = exp_hr[mask1 & mask2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # agg_hr\n",
    "# agg_hr = fil_hr.groupby('date').bpm.agg([get_top5, 'mean', get_bottom5]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_am = pd.read_csv('data/am_archive.csv')\n",
    "# raw_am['date'] = raw_am['date'].apply(parse_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# separate sleep & nap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sti_all_sleep = stitch_drop_append(raw_all_sleep)\n",
    "\n",
    "sync_sleep_mask = \\\n",
    "((sti_all_sleep['start'].apply(lambda x: x.time()) >= datetime(1,1,1,17,0).time()) |\\\n",
    "(sti_all_sleep['start'].apply(lambda x: x.time()) < datetime(1,1,1,5,0).time())) &\\\n",
    "(sti_all_sleep['asleep'] >= 180)\n",
    "\n",
    "sync_nap_mask = \\\n",
    "((sti_all_sleep['start'].apply(lambda x: x.time()) >= datetime(1,1,1,22,0).time()) |\\\n",
    "(sti_all_sleep['start'].apply(lambda x: x.time()) < datetime(1,1,1,10,0).time())) &\\\n",
    "(sti_all_sleep['asleep'] < 180)\n",
    "\n",
    "async_sleep_mask = \\\n",
    "(sti_all_sleep['start'].apply(lambda x: x.time()) > datetime(1,1,1,5,0).time()) &\\\n",
    "(sti_all_sleep['start'].apply(lambda x: x.time()) < datetime(1,1,1,17,0).time()) &\\\n",
    "(sti_all_sleep['asleep'] >= 180)\n",
    "\n",
    "async_nap_mask = \\\n",
    "(sti_all_sleep['start'].apply(lambda x: x.time()) > datetime(1,1,1,10,0).time()) &\\\n",
    "(sti_all_sleep['start'].apply(lambda x: x.time()) < datetime(1,1,1,22,0).time()) &\\\n",
    "(sti_all_sleep['asleep'] < 180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_nap\n",
    "raw_nap = sti_all_sleep.loc[async_sleep_mask, :].copy()\n",
    "raw_nap.reset_index(inplace=True, drop=True)\n",
    "\n",
    "sel_nap = pd.DataFrame()\n",
    "sel_nap['date'] = raw_nap['start'].apply(lambda x: x.date())\n",
    "sel_nap['nap'] = raw_nap['asleep']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sleep  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_sleep\n",
    "raw_sleep = sti_all_sleep.loc[sync_sleep_mask, :].copy()\n",
    "raw_sleep.reset_index(inplace=True, drop=True)\n",
    "# sel_sleep\n",
    "sel_sleep = raw_sleep[['start','end','bed','deep']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and define user input start and end time\n",
    "with open('/Users/Sehokim/capstone/data/start.pkl', 'rb') as s:\n",
    "    raw_input_start = pickle.load(s)\n",
    "    \n",
    "with open('/Users/Sehokim/capstone/data/end.pkl', 'rb') as s:\n",
    "    raw_input_end = pickle.load(s)\n",
    "    \n",
    "# apn_sleep\n",
    "input_start = expand_input_time(raw_input_start)\n",
    "input_end =  expand_input_time(raw_input_end)\n",
    "input_bed = get_input_bed(input_start, input_end)\n",
    "input_list = [input_start, input_end, input_bed]\n",
    "input_dict = defaultdict()\n",
    "for k, v in zip(sel_sleep.columns, input_list):\n",
    "    input_dict[k] = v\n",
    "    \n",
    "input_df = pd.DataFrame(input_dict, index=[len(sel_sleep)])\n",
    "apn_sleep = pd.concat([sel_sleep, input_df], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum(x):\n",
    "    mask1 = exp_sleep.date < x\n",
    "    mask2 = exp_sleep.date > x-timedelta(days=3)\n",
    "    return exp_sleep.loc[mask1 & mask2, 'bed'].mean()\n",
    "\n",
    "# exp_sleep\n",
    "exp_sleep = pd.DataFrame()\n",
    "exp_sleep['date'] = apn_sleep['end'].apply(lambda x: x.date()) - timedelta(days=1)\n",
    "exp_sleep['day'] = exp_sleep['date'].apply(lambda x: x.weekday())\n",
    "exp_sleep['start'] = apn_sleep['start']\n",
    "exp_sleep['end'] = apn_sleep['end']\n",
    "exp_sleep['bed'] = apn_sleep['bed']\n",
    "exp_sleep['deep'] = apn_sleep['deep']\n",
    "exp_sleep['delta'] = get_delta_scale(apn_sleep)\n",
    "\n",
    "for i in range(7):\n",
    "    i += 1\n",
    "    exp_sleep[f'p{i}'] = get_p_day(exp_sleep, i)\n",
    "exp_sleep['p1_diff'] = get_diff(exp_sleep, 'p1')\n",
    "exp_sleep['p3_avg'] = get_avg(exp_sleep, 3)\n",
    "exp_sleep['p7_avg'] = get_avg(exp_sleep, 7)\n",
    "exp_sleep['p3_var'] = get_var(exp_sleep, 3)\n",
    "exp_sleep['p7_var'] = get_var(exp_sleep, 7)\n",
    "exp_sleep['p3_diff'] = get_diff(exp_sleep, 'p3_avg')\n",
    "exp_sleep['p7_diff'] = get_diff(exp_sleep, 'p7_avg')\n",
    "exp_sleep['p3_sum'] = exp_sleep['date'].apply(get_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge + trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = exp_sleep.merge(sel_nap, on='date', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stdsc = ChainTransformer([TimeScaler(), StandardScaler()])\n",
    "zero_stdsc = ChainTransformer([ZeroFiller(), StandardScaler()])\n",
    "avg_stdsc = ChainTransformer([AvgFiller(), StandardScaler()])\n",
    "\n",
    "branches = [\n",
    "    ('start', time_stdsc), \n",
    "    ('end', time_stdsc),\n",
    "    ('bed', StandardScaler()),\n",
    "    ('day', OneHotEncoder()),\n",
    "    ('p1', time_stdsc),\n",
    "    ('p2', time_stdsc),\n",
    "    ('p3', time_stdsc),\n",
    "    ('p4', time_stdsc),\n",
    "    ('p5', time_stdsc),\n",
    "    ('p6', time_stdsc),\n",
    "    ('p7', time_stdsc),\n",
    "    ('delta', StandardScaler()),\n",
    "    ('p3_avg', time_stdsc),\n",
    "    ('p7_avg', time_stdsc),\n",
    "    ('p3_var', StandardScaler()),\n",
    "    ('p7_var', StandardScaler()),\n",
    "    ('p1_diff', StandardScaler()),\n",
    "    ('p3_diff', StandardScaler()),\n",
    "    ('p7_diff', StandardScaler()),\n",
    "    ('nap', ZeroFiller()),\n",
    "    ('p3_sum', avg_stdsc),\n",
    "    ('deep', AvgRatioFiller(merged['bed']))\n",
    "]\n",
    "\n",
    "mp = MatrixPipeline(branches)\n",
    "mp.fit(merged)\n",
    "Xy = mp.transform(merged)\n",
    "Xy = Xy[7:].copy()\n",
    "Xy.reset_index(inplace=True, drop=True)\n",
    "y = Xy.pop('deep')\n",
    "Xy.pop('date')\n",
    "X = Xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.scatter(Xy['p3_sum'], df.deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get regularization strength\n",
    "a_space = np.logspace(np.log10(0.000001), np.log10(1000000), num=500)\n",
    "mses = []\n",
    "trainmses = []\n",
    "for a in a_space:\n",
    "    mse, r2, trainmse, trainr2, coef, intercept = estimator_cv_scores(X, y, Lasso, a, max_iter=1000)\n",
    "    mses.append(round(mse, 3))\n",
    "    trainmses.append(round(trainmse, 3))\n",
    "    \n",
    "tuned_a = a_space[np.argmin(mses)]\n",
    "print(tuned_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge test CVMSE_500: 157.70, CVR2_500: 0.27\n",
      "ridge train CVMSE_500: 154.65, CVR2_500: 0.28\n"
     ]
    }
   ],
   "source": [
    "cvmses = []\n",
    "cvr2s = []\n",
    "traincvmses = []\n",
    "traincvr2s = []\n",
    "for _ in range(500):\n",
    "    cvmse, cvr2, traincvmse, traincvr2, coef, intercept = estimator_cv_scores(X, y, Lasso, tuned_a, max_iter=1000)\n",
    "    cvmses.append(cvmse)\n",
    "    cvr2s.append(cvr2)\n",
    "    traincvmses.append(traincvmse)\n",
    "    traincvr2s.append(traincvr2)\n",
    "    \n",
    "\n",
    "# print model score\n",
    "print(f'ridge test CVMSE_500: {np.mean(cvmses):.2f}, CVR2_500: {np.mean(cvr2s):.2f}\\n'\n",
    "  f'ridge train CVMSE_500: {np.mean(traincvmses):.2f}, CVR2_500: {np.mean(traincvr2s):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.27083347685095\n"
     ]
    }
   ],
   "source": [
    "# get regularization strength\n",
    "a_space = np.logspace(np.log10(0.000001), np.log10(1000000), num=500)\n",
    "mses = []\n",
    "trainmses = []\n",
    "for a in a_space:\n",
    "    mse, r2, trainmse, trainr2, coef, intercept = estimator_cv_scores(X, y, Ridge, a)\n",
    "    mses.append(round(mse, 3))\n",
    "    trainmses.append(round(trainmse, 3))\n",
    "    \n",
    "tuned_a = a_space[np.argmin(mses)]\n",
    "print(tuned_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge test CVMSE_500: 164.08, CVR2_500: 0.23\n",
      "ridge train CVMSE_500: 147.67, CVR2_500: 0.32\n"
     ]
    }
   ],
   "source": [
    "cvmses = []\n",
    "cvr2s = []\n",
    "traincvmses = []\n",
    "traincvr2s = []\n",
    "for _ in range(500):\n",
    "    cvmse, cvr2, traincvmse, traincvr2, coef, intercept = estimator_cv_scores(X, y, Ridge, tuned_a)\n",
    "    cvmses.append(cvmse)\n",
    "    cvr2s.append(cvr2)\n",
    "    traincvmses.append(traincvmse)\n",
    "    traincvr2s.append(traincvr2)\n",
    "    \n",
    "\n",
    "# print model score\n",
    "print(f'ridge test CVMSE_500: {np.mean(cvmses):.2f}, CVR2_500: {np.mean(cvr2s):.2f}\\n'\n",
    "  f'ridge train CVMSE_500: {np.mean(traincvmses):.2f}, CVR2_500: {np.mean(traincvr2s):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_1       : 0.0\n",
      "is_3       : 0.0\n",
      "is_4       : 0.0\n",
      "is_5       : 0.0\n",
      "is_6       : -0.0\n",
      "is_2       : 0.0\n",
      "is_0       : -0.0\n",
      "start_sin  : -0.0\n",
      "start_cos  : -0.0\n",
      "end_sin    : 0.0\n",
      "end_cos    : -0.0\n",
      "bed        : 6.998826020107766\n",
      "delta      : 0.0\n",
      "p1_sin     : -0.0\n",
      "p1_cos     : -0.0\n",
      "p2_sin     : 0.0\n",
      "p2_cos     : 0.0\n",
      "p3_sin     : -0.0\n",
      "p3_cos     : -0.0\n",
      "p4_sin     : -0.0\n",
      "p4_cos     : -0.0\n",
      "p5_sin     : -0.0\n",
      "p5_cos     : -0.2643110087328162\n",
      "p6_sin     : -0.0\n",
      "p6_cos     : -0.0\n",
      "p7_sin     : 0.0\n",
      "p7_cos     : 0.0\n",
      "p1_diff    : -0.0\n",
      "p3_avg_sin : 0.0\n",
      "p3_avg_cos : -0.0\n",
      "p7_avg_sin : -0.0\n",
      "p7_avg_cos : -0.0\n",
      "p3_var     : -0.0\n",
      "p7_var     : 0.0\n",
      "p3_diff    : -0.0\n",
      "p7_diff    : -0.0\n",
      "p3_sum     : -0.0\n",
      "nap        : 0.0\n"
     ]
    }
   ],
   "source": [
    "# print beta coef\n",
    "beta = list(zip(X.columns, map(lambda x: round(x, 99), coef)))\n",
    "for b, c in beta:\n",
    "    print(f'{b:10} : {c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict today "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict today\n",
    "Xtest = X.iloc[:-1, :].values\n",
    "ytest = y.iloc[:-1].values\n",
    "Xtoday = X.iloc[-1, :].values.reshape(1,-1)\n",
    "ridge = Ridge(a)\n",
    "ridge.fit(Xtest, ytest)\n",
    "y_ = ridge.predict(Xtoday)[0]\n",
    "y_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
